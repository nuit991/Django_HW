PChome當作範例

1.
views.py更改
為了先顯示結果畫面，改成這樣，不用在這邊抓資料，後面會從consumers.py去抓資料

def search_pchome_product_view(request):
    #request : HTTP 请求的所有信息，在目前情況下進到http://127.0.0.1:8000/search-form-pchome/這個網頁，輸入要搜尋的名稱，這樣就算是一種request (?
    if request.method == 'POST':
        #用来检查当前 HTTP 请求的方法是否为 POST，參考下方HTTP 请求方法
        product_name = request.POST.get('product_name')
        scroll_count = int(request.POST.get('scroll_count', 5))
        #product_name 是從 <label for="product_name">請輸入要搜索的商品名稱：</label> 輸入得到
        #.get('product_name') 方法用于从 request.POST 字典中获取键为 product_name 的值。
        

        context = {
            'results': results,
            'total_items': total_items,
        }

        #调用 scrape_pchome_product 的函数，并将 product_name 作为参数传递给该函数。
        return render(request, 'search_results_pchome.html', context)

--------------------
2.
urls.py不用更改

--------------------
3.
routing.py更改

#这行代码导入了 re_path 函数，它允许使用正则表达式来定义 URL 模式。
#re_path 是 Django 的 URL 解析器之一，可以更灵活地匹配复杂的 URL 模式。
from django.urls import re_path
#. (dot) 代表当前包或模块所在的目录。
#假設在A Folder下面就要用 from .A
from . import consumers, consumers_momo
#这是一个列表，用于存放 WebSocket URL 的路由配置。这个列表会在 Django 的 ASGI 配置中被引用，以确定哪些 URL 应该由哪些 WebSocket 消费者处理。
websocket_urlpatterns = [
    #这个 URL 模式使用了 re_path 函数，并定义了一个 WebSocket 路由。
    #r'ws/counter/': 这是一个原始字符串（原始字符串以 r 开头），它定义了匹配的 URL 模式。在这个例子中，ws/counter/ 是 WebSocket 连接的路径
    #如果客户端连接到 ws://yourdomain/ws/counter/，这个 URL 会被匹配。
    #consumers.CounterConsumer.as_asgi(): 这是一个 WebSocket 消费者类，CounterConsumer 通过 as_asgi() 方法被转换为一个 ASGI 应用，以处理 WebSocket 请求。
    #CounterConsumer 类负责处理在 ws/counter/ 路径上收到的所有 WebSocket 请求。 (會去找consumsers.py)
    re_path(r'ws/counter/', consumers.CounterConsumer.as_asgi()),
    re_path(r'ws/momo/', consumers_momo.Momo_Consumer.as_asgi()),
    re_path(r'ws/pchome/', consumers_momo.Pchome_Consumer.as_asgi()),

]

--------------------
4.
consumers_pchome.py 設定

#import asyncio: 导入 asyncio 模块，它是 Python 的标准库，用于编写异步代码，尤其是处理协程、事件循环等。
import asyncio
#import json: 导入 json 模块，用于处理 JSON 数据的序列化和反序列化（即将 Python 对象转换为 JSON 字符串，以及从 JSON 字符串中恢复 Python 对象）。
import json
#from channels.generic.websocket import AsyncWebsocketConsumer: 从 channels 库中导入 AsyncWebsocketConsumer 类。
#AsyncWebsocketConsumer 是 Django Channels 中的一个基类，用于创建处理 WebSocket 连接的消费者。它提供了处理 WebSocket 消息、连接和断开的异步方法。
#channels 註解寫在下面
from channels.generic.websocket import AsyncWebsocketConsumer
from .data_scraper_buy_pchome import search_pchome_product as scrape_pchome_product

#Momo_Consumer 继承自 AsyncWebsocketConsumer，这是 Django Channels 提供的一个类，用于处理 WebSocket 连接的异步操作。
class Pchome_Consumer(AsyncWebsocketConsumer):
    #这是一个异步方法，用于处理 WebSocket 连接的建立。connect 方法会在 WebSocket 客户端尝试连接到服务器时被调用。
    async def connect(self):
        #设置实例属性 channel_name，用于标识这个 WebSocket 连接所属的频道。在这个例子中，channel_name 被设置为 'momo_channel'。这个属性可以用来管理和区分不同的 WebSocket 连接或频道。
        self.channel_name = 'pchome_channel'
        #这行代码会在服务器端的控制台输出 'momo_channel'。这是一个调试输出，帮助开发人员确认 connect 方法被调用时的状态。实际开发中，这个输出可以帮助你验证 WebSocket 连接是否成功建立。
        print('pchome_channel')
        #await 关键字表示这是一个异步操作。self.accept() 是一个异步方法，用于接受 WebSocket 连接。调用这个方法会发送一个响应给客户端，确认 WebSocket 连接已经被接受并可以开始进行数据通信。
        #只有在调用了 accept() 方法后，客户端才能向服务器发送数据。
        await self.accept()  # 接受 WebSocket 连接


    #disconnect 是 WebSocket 消费者的一个异步方法，当 WebSocket 连接关闭时会被调用。它的参数 close_code 是一个整数，表示关闭连接的原因代码（例如，正常关闭、协议错误等）。
    async def disconnect(self, close_code):
        #hasattr 函数用于检查对象 self 是否具有指定的属性(白話一點就是這樣self.product_task)。在这里，hasattr(self, 'product_task') 检查 self 对象是否有名为 product_task 的属性。
        #self.product_task 是之前在消费者中创建的异步任务的引用，通常是在 connect 方法中创建的任务。
        if hasattr(self, 'product_task'):
            #如果 self 对象有 product_task 属性（即 self.product_task 存在），self.product_task.cancel() 会被调用以取消该任务。
            #cancel() 方法用于请求取消异步任务。这并不会立即终止任务，而是向任务发送取消请求。任务会在下一个检查点检查取消请求，并在适当的时候停止执行。
            self.product_task.cancel()



    #流程: 接收数据 -> 解析数据 -> 创建并调度异步任务。
    #用于处理 WebSocket 客户端发送到服务器的消息。
    async def receive(self, text_data):  #text_data->前端丟的數據，這邊就是指product_name / max_pages
        #打印接收到的消息。这有助于调试，查看从客户端接收到的数据是什么。
        print(f"Received data: {text_data}")
        #将接收到的 JSON 字符串转换为 Python 字典。json.loads 函数用于解析 JSON 字符串并返回相应的字典对象。
        data = json.loads(text_data)
        #从解析后的字典中获取 product_name 的值。data.get 方法用于获取字典中的值，如果键不存在，则返回 None。
        product_name = data.get('product_name')
        #从字典中获取 max_pages 的值，并将其转换为整数。data.get('max_pages', 5) 意味着，如果 max_pages 键不存在，则默认值为 5。int 函数将其转换为整数类型。
        scroll_count = int(data.get('scroll_count', 5))
        #使用 asyncio.create_task 创建一个新的异步任务，调用 self.send_product_data 方法。
        #asyncio.create_task 用于调度异步任务，self.product_task 保存了这个任务对象，以便后续可以取消或检查任务的状态。
        self.product_task = asyncio.create_task(self.send_product_data(product_name, scroll_count))



    #定义一个异步方法 send_product_data，用于处理产品数据的发送。
    async def send_product_data(self, product_name, max_pages):
        print("send_product_data called")
        #使用异步 for 循环从 scrape_momo_product 函数获取产品数据。
        async for prd_name, product_url, price, img_url in scrape_pchome_product(product_name, scroll_count): 
            data = {
                'prd_name': prd_name,
                'product_url': product_url,
                'price': price,
                'img_url': img_url
            }
            print('CCCC___Sending data:', data) 
            #通过 WebSocket 发送数据给客户端。
            #json.dumps(data) 将数据字典转换为 JSON 格式的字符串，self.send() 是 WebSocket 消费者提供的方法，用于发送消息。
            await self.send(text_data=json.dumps(data)) 
            await asyncio.sleep(1)  # 延迟，避免发送过快
        #20240816
        #告诉前端数据抓取已经完成
        print("Sending completion status")
        await self.send(text_data=json.dumps({'status': 'completed'}))

--------------------
5.
修改爬蟲，增加異步處理
主要是抓資料的部分跟主程式的部分

以Pchome為例:

# 抓出商品名称 / Url / 价格 / 图片
async def extract_items(driver, item_container):
    item_list = []
    list_items_name = item_container.find_elements(By.CLASS_NAME, "prod_name")
    list_items_price = item_container.find_elements(By.CLASS_NAME, "price")
    list_items_picture = item_container.find_elements(By.CLASS_NAME, "prod_img")

    for name_element, price_element, picture_element in zip(list_items_name, list_items_price, list_items_picture):
        item_text = name_element.text.strip()
        link_element = name_element.find_element(By.TAG_NAME, "a") if name_element.find_elements(By.TAG_NAME, "a") else None
        item_url = link_element.get_attribute("href") if link_element else "无链接"

        price_text = price_element.text.strip()
        picture_src = picture_element.find_element(By.TAG_NAME, "img").get_attribute("src")

        yield prd_name, product_url, price, img_url
        await asyncio.sleep(1)  # 模拟数据生成的延迟



# 主程序
async def search_pchome_product(product_name, scroll_count):
    retries = 5  # 设置最大重试次数
    attempt = 0

    while attempt < retries:
        try:
            driver = initialize_driver()
            search_product(driver, product_name)
            item_container = scroll_and_load_more(driver, scroll_count)
            item_list = extract_items(driver, item_container)

            async for prd_name, product_url, price, img_url in extract_items(driver, item_container):
                yield prd_name, product_url, price, img_url
                await asyncio.sleep(1)  

            break


        except Exception as e:
            print(f"Exception occurred: {str(e)}")
            attempt += 1
            print(f"Retry attempt {attempt}...")

        finally:
            driver.quit()
            time.sleep(2)  # 等待2秒再重试

    print("Reached maximum retries. Returning empty list.")
    return [], 0













